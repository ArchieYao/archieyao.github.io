<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Flink on 大道至简</title>
    <link>http://localhost:1313/tags/flink/</link>
    <description>Recent content in Flink on 大道至简</description>
    <generator>Hugo</generator>
    <language>cn-zh</language>
    <lastBuildDate>Tue, 28 Mar 2023 20:31:01 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/flink/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Flink内存模型</title>
      <link>http://localhost:1313/post/2023/03/28/flink%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 28 Mar 2023 20:31:01 +0800</pubDate>
      <guid>http://localhost:1313/post/2023/03/28/flink%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</guid>
      <description>Java 堆外内存 import sun.nio.ch.DirectBuffer; import java.nio.ByteBuffer; import java.util.concurrent.TimeUnit; public class OutHeapMem { public static void main(String[] args) throws Exception { // 分配 1G 直接内存 ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024 * 1024 * 1024); TimeUnit.SECONDS.sleep(30); System.out.println(&amp;quot;clean start&amp;quot;); // 清除直接内存 ((DirectBuffer) byteBuffer).cleaner().clean(); System.out.println(&amp;quot;clean finished&amp;quot;); TimeUnit.SECONDS.sleep(30); } } # 分配内存 Memory used total max usage heap 21M 165M 3641M 0.59% ps_eden_space 3M 64M 1344M 0.29% ps_survivor_space 0K 10752K 10752K 0.00% ps_old_gen 17M 91M 2731M 0.</description>
    </item>
    <item>
      <title>Flink类加载机制</title>
      <link>http://localhost:1313/post/2023/03/24/flink%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Fri, 24 Mar 2023 16:13:22 +0800</pubDate>
      <guid>http://localhost:1313/post/2023/03/24/flink%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</guid>
      <description>flink 类加载配置说明 Flink 作为基于 JVM 的框架，在 flink-conf.yaml 中提供了控制类加载策略的参数 classloader.resolve-order，可选项有 child-first（默认）和 parent-first。&#xA;Key Default Type Description classloader.resolve-order &amp;ldquo;child-first&amp;rdquo; String Defines the class resolution strategy when loading classes from user code, meaning whether to first check the user code jar (&amp;ldquo;child-first&amp;rdquo;) or the application classpath (&amp;ldquo;parent-first&amp;rdquo;). The default settings indicate to load classes first from the user code jar, which means that user code jars can include and load different dependencies than Flink uses (transitively).</description>
    </item>
    <item>
      <title>Flink反压</title>
      <link>http://localhost:1313/post/2023/03/23/flink%E5%8F%8D%E5%8E%8B/</link>
      <pubDate>Thu, 23 Mar 2023 16:37:37 +0800</pubDate>
      <guid>http://localhost:1313/post/2023/03/23/flink%E5%8F%8D%E5%8E%8B/</guid>
      <description>什么是反压 如果你看到一个 Task 发生 反压警告（例如： High），意味着它生产数据的速率比下游 Task 消费数据的速率要快。 在工作流中数据记录是从上游向下游流动的（例如：从 Source 到 Sink）。反压沿着相反的方向传播，沿着数据流向上游传播。&#xA;以一个简单的 Source -&amp;gt; Sink Job 为例。如果看到 Source 发生了警告，意味着 Sink 消费数据的速率比 Source 生产数据的速率要慢。 Sink 正在向上游的 Source 算子产生反压。&#xA;Task（SubTask）的每个并行实例都可以用三个一组的指标评价：&#xA;backPressureTimeMsPerSecond，subtask 被反压的时间 idleTimeMsPerSecond，subtask 等待某类处理的时间 busyTimeMsPerSecond，subtask 实际工作时间 在任何时间点，这三个指标相加都约等于1000ms。 指标值说明：&#xA;OK: 0 &amp;lt;= 比例 &amp;lt;= 0.10 LOW: 0.10 &amp;lt; 比例 &amp;lt;= 0.5 HIGH: 0.5 &amp;lt; 比例 &amp;lt;= 1 反压问题定位 可以看各个operator的metrics的指标，比如：buffers.outPoolUsage、buffers.inPoolUsage、buffers.inputFloatingBuffersUsage、buffers.inputExclusiveBuffersUsage；&#xA;接收端共用一个LocalBufferPool，接收端每个Channel在初始化阶段都会分配固定数量的Buffer(Exclusive Buffer)。如果某一时刻接收端接受到的数量太多，Exclusive Buffer就会耗尽，此时就会向BufferPool申请剩余的Floating Buffer（除了Exclusive Buffer，其他的都是Floating Buffer,备用Buffer）；inPoolUsage = floatingBuffersUsage + exclusiveBuffersUsage&#xA;若 inPoolUsage 低，而 outPoolUsage 低，则说明完全没有背压现象。 若 inPoolUsage 低，而 outPoolUsage 高，则说明处于临时状态，可能是背压刚开始，也可能是刚结束，需要再观察。 若 inPoolUsage 高，而 outPoolUsage 低，那么通常情况下这个算子就是背压的根源了。 若 inPoolUsage 高，而 outPoolUsage 高，则说明这个算子是被其他下游算子反压而来的，并不是元凶。 在反压定位过程中，建议关闭 Operator Chaining 优化，这样所有的算子可以单独拆分出来，不会相互干扰：</description>
    </item>
    <item>
      <title>Flink Append流、Retract流、Upsert流</title>
      <link>http://localhost:1313/post/2022/03/13/flink-append%E6%B5%81retract%E6%B5%81upsert%E6%B5%81/</link>
      <pubDate>Sun, 13 Mar 2022 11:16:23 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/03/13/flink-append%E6%B5%81retract%E6%B5%81upsert%E6%B5%81/</guid>
      <description>摘要： 介绍 Flink 中 Append流、Retract流、Upsert流的含义。&#xA;Append流 Retract流 Upsert流 Append流 在 Append 流中，仅通过 INSERT 操作修改的动态表，可以通过输出插入的行转换为流。&#xA;Retract流 retract 流包含两种类型的 message： add messages 和 retract messages 。&#xA;通过将INSERT 操作编码为 add message、将 DELETE 操作编码为 retract message、将 UPDATE 操作编码为更新(先前)行的 retract message 和更新(新)行的 add message，将动态表转换为 retract 流。&#xA;OPERATOR ENCODE insert add update retract -&amp;gt; add delete retract Upsert流 upsert 流包含两种类型的 message： upsert messages 和delete messages。&#xA;转换为 upsert 流的动态表需要(可能是组合的)唯一键。通过将 INSERT 和 UPDATE 操作编码为 upsert message，将 DELETE 操作编码为 delete message ，将具有唯一键的动态表转换为流。消费流的算子需要知道唯一键的属性，以便正确地应用 message。与 retract 流的主要区别在于 UPDATE 操作是用单个 message 编码的，因此效率更高。</description>
    </item>
    <item>
      <title>Flink Checkpoint机制</title>
      <link>http://localhost:1313/post/2022/03/04/flink-checkpoint%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Fri, 04 Mar 2022 11:16:23 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/03/04/flink-checkpoint%E6%9C%BA%E5%88%B6/</guid>
      <description>摘要： 如果把运行中的 Flink 程序比做一条河流，Checkpoint 就是一个相机，定期地对河流进行拍照，记录河水的状态。本文以自顶向下的视角，从理论到实现，分析 Flink 中的 Checkpoint 机制；&#xA;理论基础 asynchronous barrier snapshotting 算法步骤 算法在 Flink 中的实现 Flink Checkpoint 整体流程 Flink Checkpoint Barrier Alignment Flink Checkpoint 使用 Flink Job 重启策略 Flink Job 开启 Checkpoint 理论基础 asynchronous barrier snapshotting Flink Checkpoint 机制是异步屏障快照（asynchronous barrier snapshotting, ABS）算法的一种实现，而 ABS 算法基于 Chandy-Lamport 的变种，但数据模型是还是基于 Chandy-Lamport；&#xA;在 flink 中，作业算子被抽象为 DAG，节点为 operator，边是每一个 operator 的 stream（channel），与 Chandy-Lamport 的数据模型正好吻合；&#xA;ABS 算法把 Chandy-Lamport 中的 marker 消息换成了 barrier，作用是一致的，都是切分 snapshot；&#xA;ABS 算法 中 asynchronous 是异步的意思，当算子收齐 barrier 并触发快照之后，不会等待快照数据全部写入状态后端，而是一边后台写入，一边立刻继续处理数据流，并将 barrier 发送到下游，实现了最小化延迟。当然，引入异步性之后，所有有状态的算子都需要上报 ack，否则 JobManager 就无法确认一次 snapshot 是否完成。</description>
    </item>
    <item>
      <title>Flink时间语义</title>
      <link>http://localhost:1313/post/2022/02/25/flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/</link>
      <pubDate>Fri, 25 Feb 2022 11:16:23 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/02/25/flink%E6%97%B6%E9%97%B4%E8%AF%AD%E4%B9%89/</guid>
      <description>摘要： 理解流处理中的时间语义，处理时间和事件时间。&#xA;如图，在无界数据中，随着时间推移，数据一直产生，但真实情况中，往往在一段时间内的数据都是不均匀的，往往会出现意外的情况，比如在地铁无信号的情况下，数据虽然产生，但是会有一段时间延迟才会到达消息队列，例如虚线框中的数据。&#xA;处理时间 处理时间就是流计算处理程序的机器本地时间，按照这种时间语义，在流计算的时间窗口中，上述例子中的数据会按这样分布：&#xA;基于本地时间，在第一分钟，流处理程序只收到了 15、18 两个数据，后续数据由于网络原因，在 8:01:00 之后才到达流计算程序，所以后续数据在下一个时间窗口内。&#xA;事件时间 事件时间就是事件的发生时间，这个时间通常会在数据中，按照这种时间语义，在流计算的时间窗口中，上述例子中的数据会按这样分布：&#xA;基于事件时间，在第一分钟，数据应该是：15 18 9 10 ，在第二分钟，数据应该是：11 。&#xA;watermark 由于事件时间的窗口和事件相关，那么如果下一个事件还未到达，流计算程序是否就无限等待呢？&#xA;为了解决这个问题，flink 引入 watermark 的概念，假如定义 watermark 为 T，那么在每一个时间窗口中，T 都会单调递增 T &amp;lt; T1，并且下一个时间窗口中的事件时间必须大于 T1，那么每一个时间窗口的数据就是介于 T-T1。</description>
    </item>
    <item>
      <title>Flink基本架构</title>
      <link>http://localhost:1313/post/2022/02/23/flink%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</link>
      <pubDate>Wed, 23 Feb 2022 11:16:23 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/02/23/flink%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</guid>
      <description>摘要： 鸟瞰 Flink 架构，分析 Flink 内部组件工作机制。&#xA;Flink 架构图 提交作业流程 Flink 集群模式 JobManager Taskmanager 算子链 Slot task 数据交换策略 Flink 架构图 一个完整的 Flink 集群由一个 Jobmanager 和若干个 Taskmanager 组成，Jobmanager 主要负责调度 task 以及 协调 Checkpoint。Taskmanager 则负责具体的 task 执行，以及数据流的交换。&#xA;可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为standalone 集群启动、在容器中启动、或者通过YARN等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。&#xA;提交作业流程 以一个作业提交的流程来说明 Flink 各个组件是如何交互和工作的：&#xA;Flink 集群模式 Flink 集群类型一般有以下几种：&#xA;Flink Session 集群&#xA;这种模式下，集群自创建开始，最后到集群生命周期结束，不受作业因素影响； 集群下的多个作业共享 内存、网络、磁盘等资源，如果集群出现异常，该集群下的所有作业都会收到影响。&#xA;优点：提交作业速度很快，无需提前申请资源； 并且资源利用率较高。&#xA;缺点：作业之间隔离性较差，横向扩展不太方便。&#xA;Flink job 集群&#xA;这种模式也称 pre-job 模式，集群交由 资源管理器托管，例如 Yarn ，需要运行作业，第一步申请资源，启动一个 Flink 集群，第二步提交作业，这种模式下，每个作业会独享一个 Flink 集群。</description>
    </item>
    <item>
      <title>Flink WordCount</title>
      <link>http://localhost:1313/post/2022/02/22/flink-wordcount/</link>
      <pubDate>Tue, 22 Feb 2022 18:16:23 +0000</pubDate>
      <guid>http://localhost:1313/post/2022/02/22/flink-wordcount/</guid>
      <description>摘要：Flink 从零开始，下载集群并运行 WordCount Job。 完整代码地址： https://github.com/ArchieYao/flink-learning/tree/main/hello-world&#xA;Flink 本地模式集群安装 运行Flink，需提前安装好 Java 8 或者 Java 11。&#xA;wget https://dlcdn.apache.org/flink/flink-1.14.3/flink-1.14.3-bin-scala_2.12.tgz tar -zxvf flink-1.14.3-bin-scala_2.12.tgz cd flink-1.14.3 ./bin/start-cluster.sh 运行成功后，可以在 IP:8081 访问 Flink-UI&#xA;Flink Word Count job source 是多段文本，类型： DataSource ，经过 flatMap，切分为每个单词，然后转换为：(val,n) 的数据，然后根据 val 分组统计，得出 sum(n) 的值。&#xA;public static void main(String[] args) throws Exception { // 创建Flink任务运行环境 final ExecutionEnvironment executionEnvironment = ExecutionEnvironment.getExecutionEnvironment(); // 创建DataSet，数据是一行一行文本 DataSource&amp;lt;String&amp;gt; text = executionEnvironment.fromElements( &amp;quot;Licensed to the Apache Software Foundation (ASF) under one&amp;quot;, &amp;quot;or more contributor license agreements.</description>
    </item>
  </channel>
</rss>

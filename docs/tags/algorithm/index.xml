<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithm on Hugo Prose</title>
    <link>/tags/algorithm/</link>
    <description>Recent content in Algorithm on Hugo Prose</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-zh</language>
    <lastBuildDate>Wed, 09 Aug 2023 10:39:17 +0800</lastBuildDate><atom:link href="/tags/algorithm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DBLog 阅读笔记</title>
      <link>/post/2023/08/09/dblog-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 09 Aug 2023 10:39:17 +0800</pubDate>
      
      <guid>/post/2023/08/09/dblog-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>介绍 算法流程 参考 https://arxiv.org/pdf/2010.12597.pdf</description>
    </item>
    
    <item>
      <title>The Dataflow Model 阅读笔记</title>
      <link>/post/2023/05/16/the-dataflow-model-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Tue, 16 May 2023 15:26:10 +0800</pubDate>
      
      <guid>/post/2023/05/16/the-dataflow-model-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</guid>
      <description>Dataflow 计算模型 Dataflow 的核心计算模型非常简单，它只有两个概念，一个叫做 ParDo，就是并行处理的意思；另一个叫做 GroupByKey，也就是按照 Key 进行分组。
ParDo ParDo 用来进行通用的并行化处理。每个输入元素（这个元素本身有可能是一个有限的集合）都会使用一个 UDF 进行处理（在Dataflow中叫做DoFn），输出是0或多个输出元素。这个例子是把键的前缀进行展开，然后把值复制到展开后的键构成新的键值对并输出。
GroupByKey GroupByKey 用来按 Key 把元素重新分组。
ParDo 操作因为是对每个输入的元素进行处理，因此很自然地就可以适用于无边界的数据。而 GroupByKey 操作，在把数据发送到下游进行汇总前，需要收集到指定的键对应的所有数据。如果输入源是无边界的，那么我们不知道何时才能收集到所有的数据。所以通常的解决方案是对数据使用窗口操作。
窗口 时间语义 窗口通常基于时间，时间对于窗口来说是必不可少的，在流式计算中，有 processing-time 和 event-time 两种时间语义，具体参考： 时间语义
窗口分类 固定窗口（Fixed Window）固定区间（互不重叠）的窗口，可以基于时间，也可以基于数量；将事件分配到不同区间的窗口中，在通过窗口边界后，窗口内的所有事件会发送给计算函数进行计算；
滑动窗口（Sliding Window）固定区间但可以重叠的窗口，需要指定窗口区间以及滑动步长，区间重叠意味着同一个事件会分配到不同窗口参与计算。 窗口区间决定何时触发计算，滑动步长决定何时创建一个新的窗口；
会话窗口（Session Window）会话窗口通常基于用户的会话，通过定义会话的超时时间，将事件分割到不同的会话中； 例如，有个客服聊天系统，如果用户超过 30 分钟没有互动，则认为一次会话结束，当客户下次进入，就是一个新的会话了。
窗口分配与合并 Dataflow 模型里，需要的不只是 GroupByKey，实际在统计数据的时候，往往需要的是 GroupByKeyAndWindow。统计一个不考虑任何时间窗口的数据，往往是没有意义的； Dataflow 模型提出：
从模型简化的角度上，把所有的窗口策略都当做非对齐窗口，而底层实现来负责把对齐窗口作为一个特例进行优化。 窗口操作可以被分隔为两个互相相关的操作： set&amp;lt;Window&amp;gt; AssignWindows(T datum) 即窗口分配操作。这个操作把元素分配到 0 或多个窗口中去。 set&amp;lt;window&amp;gt; MergeWindows(Set&amp;lt;Window&amp;gt; windows) 即窗口合并操作，这个操作在汇总时合并窗口。 而在实际的逻辑实现层面，Dataflow 最重要的两个函数，也就是 AssignWindows 函数和 MergeWindows 函数。 窗口分配 每一个原始的事件，在业务处理函数之前，其实都是（key, value, event_time）这样一个三元组。而 AssignWindows 要做的，就是把这个三元组，根据我们的处理逻辑，变成（key, value, event_time, window）这样的四元组。</description>
    </item>
    
    <item>
      <title>堆和堆排序</title>
      <link>/post/2023/05/12/%E5%A0%86%E5%92%8C%E5%A0%86%E6%8E%92%E5%BA%8F/</link>
      <pubDate>Fri, 12 May 2023 17:01:04 +0800</pubDate>
      
      <guid>/post/2023/05/12/%E5%A0%86%E5%92%8C%E5%A0%86%E6%8E%92%E5%BA%8F/</guid>
      <description>堆 堆的本质是树，用数组表示的完全二叉树；
定义 一棵深度为k且有 2^k - 1 个结点的二叉树称为满二叉树。
根据二叉树的性质2, 满二叉树每一层的结点个数都达到了最大值, 即满二叉树的第i层上有 2^(i-1) 个结点 (i≥1) 。
如果对满二叉树的结点进行编号, 约定编号从根结点起, 自上而下, 自左而右。则深度为k的, 有n个结点的二叉树, 当且仅当其每一个结点都与深度为k的满二叉树中编号从1至n的结点一一对应时, 称之为完全二叉树。
从满二叉树和完全二叉树的定义可以看出, 满二叉树是完全二叉树的特殊形态, 即如果一棵二叉树是满二叉树, 则它必定是完全二叉树。
参考： https://baike.baidu.com/item/%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91/7773232
性质 arr：[2 3 4 52 2 2 1] idx： 0 1 2 3 4 5 6 i 下标和元素之间的映射关系：
左子节点：2*i+1 右子节点：2*i+2 父节点：(i-1)/2 大根堆 完全二叉树里，每一个子树的最大值是根节点；
小根堆 完全二叉树里，每一个子树的最小值是根节点；
堆排序 定义堆 // maxHeap 定义一个大根堆 type maxHeap struct { Data []int Count int } func NewMaxHeap(size int) *maxHeap { return &amp;amp;maxHeap{ Data: make([]int, size), Count: 0, } } 插入数据 插入数据时，是往数组最后增加元素，由于需要保证大根堆的性质，如果新加入的元素比父节点大，则跟父节点交换位置，以此类推，一直到根节点，这个交换流程完成后，新元素插入就完成了。</description>
    </item>
    
    <item>
      <title>Chandy-Lamport 算法笔记</title>
      <link>/post/2023/05/08/chandy-lamport-%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Mon, 08 May 2023 22:38:42 +0800</pubDate>
      
      <guid>/post/2023/05/08/chandy-lamport-%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</guid>
      <description>前言 Global Snapshot（Global State）：全局快照，分布式系统在 Failure Recovery 的时候非常有用，也是广泛应用在分布式系统，更多是分布式计算系统中的一种容错处理理论基础。
在 Chandy-Lamport 算法中，为了定义分布式系统的 Global Snapshot，先将分布式系统简化成有限个进程和进程之间的 channel 组成，也就是一个有向图 （GAG）：节点是进程，边是 channel。因为是分布式系统，也就是说，这些进程是运行在不同的物理机器上的。那么一个分布式系统的 Global Snapshot 就是有进程的状态和 channel 中的 message 组成，这个也是分布式快照算法需要记录的。因此，Chandy-Lamport 算法解决了分布式系统在 Failure Recovery 时，可以从 Global Snapshot 中恢复的问题；
算法过程 前提条件及定义 process（Pn）：分布式系统中的进程，用 P1，P2，P3 表示； channel：分布式系统中，Pn 与 Pm 通信的管道，C12 表示从 P1 到 P2 的 channel，反之，C32 表示从 P3 到 P2的 channel； message：分布式系统中，Pn 与 Pm 之间发送的业务消息；M23 表示从 P2 到 P3 的 message； marker：在 Chandy-Lamport 算法中，Pn 与 Pm 之间发送的标记消息，不同于业务的 message，marker 是由 Chandy-Lamport 算法定义，用于帮助实现快照算法； snapshot/state：都表示快照，同时包括进程本身的状态和 message；下文中统一全局快照叫 snapshot，process 本地快照叫 state； Chandy-Lamport 算法有一些前提条件：</description>
    </item>
    
    <item>
      <title>Go语言实现 bitmap</title>
      <link>/post/2023/04/28/go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0-bitmap/</link>
      <pubDate>Fri, 28 Apr 2023 11:24:38 +0800</pubDate>
      
      <guid>/post/2023/04/28/go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0-bitmap/</guid>
      <description>算法说明 Bitmap算法是一种基于位运算的数据结构，用于解决大规模数据的快速查找和统计问题。其基本原理是将一个大数据集合映射到一个二进制向量中，其中每个元素对应于数据集合中的一个元素，向量中的每一位表示该元素是否存在于集合中。
具体来说，Bitmap算法通过使用一个位图（bitmap）来表示一个数据集合，其中每个元素对应一个位。如果某个元素在数据集合中出现，则将其对应的位设置为1，否则将其对应的位设置为0。通过这种方式，可以快速地进行集合操作，如并集、交集和差集等。
Bitmap算法的主要优点在于其空间效率高，可以用较小的空间存储大规模数据集合。另外，Bitmap算法的时间复杂度也非常低，可以快速地进行集合操作。
如何用数组表示一个 bitmap 以 1byte 为例：8位能表示8个元素， 0-7 号对应了 b[0] 下标， 8-15 号对应了 b[1] 下标，以此类推。
因此，数组下标 n 跟bitmap元素序号 bitmapIdx 的关系为：n = bitmapIdx &amp;gt;&amp;gt; 3
值如何映射到 bitmap 数组 当找到了 元素序号 n 在数组中的下标之后，如何给 b[n] 赋值呢？
1 &amp;lt;&amp;lt; (bitmapIdx &amp;amp; 7) 等同于 1 &amp;lt;&amp;lt; (bitmapIdx % 8)
(bitmapIdx % 8) 找到在了在数组 b[n] 中的第 m 位，然后 1 &amp;lt;&amp;lt; m 之后，就相当于给数组赋值，把第 m 位 置为1。
验证 同样以 1byte 为例：借用上述结论，第 24 号元素，对应的数组下标 n 为：n = 24 &amp;gt;&amp;gt; 3 结果为3, b[3]；</description>
    </item>
    
    <item>
      <title>Go语言实现 LRU</title>
      <link>/post/2023/04/27/go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0-lru/</link>
      <pubDate>Thu, 27 Apr 2023 21:43:12 +0800</pubDate>
      
      <guid>/post/2023/04/27/go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0-lru/</guid>
      <description>LRU（Least Recently Used）算法，即最近最少使用算法;其基本思想是，如果一个数据最近被访问过，那么它在未来被访问的概率也会很高；反之，如果一个数据很久都没有被访问过，那么它在未来被访问的概率就相对较低。因此，LRU算法选择淘汰最近最少使用的数据，即选择最长时间没有被访问过的数据进行淘汰。
具体来说，LRU算法通常使用一个双向链表和一个哈希表来实现。双向链表中的节点按照最近访问时间的顺序排列，最近访问的节点排在链表头部，最久未访问的节点排在链表尾部。哈希表中存储每个节点的地址，以便快速查找和删除。
当需要访问一个数据时，LRU算法首先在哈希表中查找该数据，如果存在，则将对应的节点移动到链表头部；如果不存在，则将该数据添加到链表头部，并在哈希表中创建对应的节点。
当需要淘汰数据时，LRU算法选择链表尾部的节点进行淘汰，并在哈希表中删除对应的节点。
golang 实现 LRU 算法：
package lru import ( &amp;quot;container/list&amp;quot; &amp;quot;errors&amp;quot; &amp;quot;sync&amp;quot; ) // LRU implements a non-thread safe fixed size LRU cache type LRU struct { size int evictList *list.List items map[interface{}]*list.Element } // entry is used to hold a value in the evictList type entry struct { key interface{} value interface{} } // NewLRU constructs an LRU of the given size func NewLRU(size int) (*LRU, error) { if size &amp;lt;= 0 { return nil, errors.</description>
    </item>
    
    <item>
      <title>ProtoBuf数据协议</title>
      <link>/post/2022/01/11/protobuf%E6%95%B0%E6%8D%AE%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Tue, 11 Jan 2022 00:18:23 +0000</pubDate>
      
      <guid>/post/2022/01/11/protobuf%E6%95%B0%E6%8D%AE%E5%8D%8F%E8%AE%AE/</guid>
      <description>摘要：ProtoBuf(Protocol Buffers)是一种跨平台、语言无关、可扩展的序列化结构数据的方法，可用于网络数据交换及数据存储。
Protocol Buffers介绍 不同于 XML 、JSON 这种文本格式数据，Protocol Buffers 是一种二进制格式数据。在Protocol Buffers 诞生之初，就被赋予两个特点：
向前兼容，很容易引入新字段，应对字段的频繁变更 数据格式具备描述性，并且支持多语言处理 传输效率高 基于以上这些特性，Protocol Buffers 被广泛应用于各种 RPC 框架中，并且是 Google 的数据通用语言。
Protocol Buffers协议文件 Protocol Buffers 在使用前需要先定义好协议文件，以 .proto 为后缀的文件就是Protocol Buffers 的协议文件。
Example:
// 指定protobuf的版本，proto3是最新的语法版本 syntax = &amp;quot;proto3&amp;quot;; // 定义数据结构，message 你可以想象成java的class，c语言中的struct message Response { string data = 1; // 定义一个string类型的字段，字段名字为data, 序号为1 int32 status = 2; // 定义一个int32类型的字段，字段名字为status, 序号为2 } 如果 A 和 B 要基于 Protocol Buffers 协议进行通信，那么在通信前，A 和 B 都需要有同一份协议文件，所以在 Protocol Buffers 数据传输过程中，不需要数据的 Schema 信息；</description>
    </item>
    
    <item>
      <title>逆波兰表达式算法</title>
      <link>/post/2019/09/04/%E9%80%86%E6%B3%A2%E5%85%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AE%97%E6%B3%95/</link>
      <pubDate>Wed, 04 Sep 2019 00:18:23 +0000</pubDate>
      
      <guid>/post/2019/09/04/%E9%80%86%E6%B3%A2%E5%85%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%AE%97%E6%B3%95/</guid>
      <description>摘要：将中缀表达式转化为后缀表达式，以及计算后缀表达式的算法。
import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.util.HashSet; import java.util.Scanner; import java.util.Stack; /** * @author YaoQi * Date: 2019/1/5 15:45 * Modified: * Description: 中缀表达式转后缀表达式 */ public class InfixToSuffixHandler { private static final Logger logger = LoggerFactory.getLogger(InfixToSuffixHandler.class); private static HashSet&amp;lt;Character&amp;gt; opStr = new HashSet&amp;lt;&amp;gt;(); static { logger.info(&amp;quot;Initialization operator&amp;quot;); opStr.add(&#39;+&#39;); opStr.add(&#39;-&#39;); opStr.add(&#39;*&#39;); opStr.add(&#39;/&#39;); logger.info(&amp;quot;Initialization finished&amp;quot;); } /** * 判断字符是否为操作符 * * @param c 字符 * @return */ private static boolean isOpStr(char c) { return opStr.</description>
    </item>
    
  </channel>
</rss>
